{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0b9222f",
   "metadata": {},
   "source": [
    "# VaR System: Simulated Dataset and Design Spec\n",
    "In this notebook we will create a simulated dataset of a trading firm's positions and their associated simulated historical PnL for use in computing VaR of individual portfolios and custom groupings. We'll then spec out a system to compute VaR on arbitrary sub-aggregations.\n",
    "\n",
    "## Disclaimer\n",
    "This notebook contains no MLP proprietary data and does not depend on any external data sources inside or outside MLP. All data is purely hypothetical, generated from random distributions to simulate the broad scale and shape of the dataset we are working with. It is intended for use in an academic software engineering and design project and should not be interpreted as having any similarity to MLP's actual position and PnL data at the current time or at any time in the past."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018ac73d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4c1c5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import string\n",
    "import csv\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from scipy.stats import t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9d8f757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rough scale of the data set we are working with\n",
    "n_securities = 200000\n",
    "n_positions = 2000000\n",
    "n_desks = 20\n",
    "n_pods = 200\n",
    "n_traders = 2000\n",
    "n_micros = 20000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517333f3",
   "metadata": {},
   "source": [
    "## 1. Generate a Security Universe\n",
    "First order of business is to create a universe of tradable securities that our investment professionals can take positions in. We will create 200,000 hypothetical securities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36ad21bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_samples(n_samples, distinct_strings):\n",
    "    \"\"\"\n",
    "    Generates the desired number of samples from a provided list of distinct strings, such that the result is approximately\n",
    "    Gaussian, and the frequencies of the samples are not uniform. This is a better approximation of real datasets than an even\n",
    "    random sample, and will allow us to more easily test the performance of the system for queries that have heterogeneous\n",
    "    result set sizes.\n",
    "    \"\"\"\n",
    "    # Create a probability distribution that approximates a Gaussian distribution\n",
    "    n_distinct = len(distinct_strings)\n",
    "    mean = n_distinct / 2\n",
    "    std_dev = n_distinct / 4\n",
    "    x = np.linspace(0, n_distinct - 1, n_distinct)\n",
    "    weights = np.exp(-((x - mean) ** 2) / (2 * std_dev ** 2))\n",
    "    weights /= np.sum(weights)  # Normalize the weights so they sum up to 1\n",
    "\n",
    "    return np.random.choice(distinct_strings, size=n_samples, p=weights)\n",
    "\n",
    "def generate_random_strings(n, length):\n",
    "    \"\"\"\n",
    "    Generates the desired number of strings of the specified length, constructed from random alphanumeric characters. \n",
    "    The list is guaranteed to contain distinct values, no repeats.\n",
    "    \"\"\"\n",
    "    base = string.ascii_uppercase + string.digits\n",
    "    random_strings = set()\n",
    "    \n",
    "    while len(random_strings) < n:\n",
    "        rnd_string = ''.join(random.choice(base) for _ in range(length))\n",
    "        random_strings.add(rnd_string)\n",
    "        \n",
    "    return list(random_strings)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70dbe61b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['IWWSMODR', 'MQ4D9Z22', 'OXKH7BOH', '0PX4N5MM', 'T5RQZIZS']\n"
     ]
    }
   ],
   "source": [
    "security_id_space = generate_random_strings(n_securities, 8)\n",
    "print(security_id_space[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a9540e8c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3652\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/_libs/index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/_libs/index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 19\u001b[0m\n\u001b[1;32m      1\u001b[0m security_universe \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msecurityid\u001b[39m\u001b[38;5;124m\"\u001b[39m: security_id_space,\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massetclass\u001b[39m\u001b[38;5;124m\"\u001b[39m: generate_samples(n_securities, [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEquity\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFixedIncome\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMortgage\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCommodity\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDigital\u001b[39m\u001b[38;5;124m\"\u001b[39m]),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124missuercountryofrisk\u001b[39m\u001b[38;5;124m\"\u001b[39m: generate_samples(n_securities, generate_random_strings(\u001b[38;5;241m80\u001b[39m, \u001b[38;5;241m8\u001b[39m))\n\u001b[1;32m     17\u001b[0m })\n\u001b[0;32m---> 19\u001b[0m \u001b[43msecurity_universe\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3761\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3763\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3656\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3657\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3658\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3659\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3660\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "security_universe = pd.DataFrame({\n",
    "    \"securityid\": security_id_space,\n",
    "    \"assetclass\": generate_samples(n_securities, [\"Equity\", \"FixedIncome\", \"Mortgage\", \"Commodity\", \"Digital\"]),\n",
    "    \"securitytype\": generate_samples(n_securities, [\"Stock\", \"Bond\", \"Future\", \"Option\", \"ETF\", \"Swap\", \"CDS\", \"Index\"]),\n",
    "    \"tradingcountry\": generate_samples(n_securities, [\"US\", \"GB\", \"JP\", \"FR\", \"ES\", \"IT\", \"AU\", \"GR\", \"BR\", \"IN\", \"CN\", \"CH\", \"CA\"]),\n",
    "    \"tradingcurrency\": generate_samples(n_securities, [\"USD\", \"GBP\", \"JPY\", \"EUR\", \"INR\", \"CNY\", \"CHF\", \"CAD\", \"AUD\"]),\n",
    "    \"issuername\": generate_samples(n_securities, generate_random_strings(1757, 8)),\n",
    "    \"ticker\": generate_samples(n_securities, generate_random_strings(1393, 8)),\n",
    "    \"rating\": generate_samples(n_securities, [\"AAA\", \"AA\", \"A\", \"BBB\", \"BB\", \"B\", \"CCC\", \"CC\", \"C\"]),\n",
    "    \"industrygroup\": generate_samples(n_securities, generate_random_strings(25, 8)),\n",
    "    \"industry\": generate_samples(n_securities, generate_random_strings(74, 8)),\n",
    "    \"securityname\": generate_samples(n_securities, generate_random_strings(920, 8)),\n",
    "    \"maturitydate\": generate_samples(n_securities, generate_random_strings(1368, 8)),\n",
    "    \"underlyingname\": generate_samples(n_securities, generate_random_strings(949, 8)),\n",
    "    \"regionname\": generate_samples(n_securities, [\"Americas\", \"EMEA\", \"Asia\"]),\n",
    "    \"issuercountryofrisk\": generate_samples(n_securities, generate_random_strings(80, 8))\n",
    "})\n",
    "\n",
    "security_universe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb388150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "securitytype\n",
      "ETF       41952\n",
      "Option    36980\n",
      "Swap      36868\n",
      "Future    25621\n",
      "CDS       25236\n",
      "Index     13911\n",
      "Bond      13724\n",
      "Stock      5708\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check the distribution shape\n",
    "print(security_universe['securitytype'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "507ffaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a csv for securities \n",
    "with open('./data/securities.csv', 'w', newline='') as csvfile:\n",
    "    # columns for the securities dataframe (security_universe.columns)\n",
    "    securities_cols = ['securityid', 'assetclass', 'securitytype', 'tradingcountry',\n",
    "       'tradingcurrency', 'issuername', 'ticker', 'rating', 'industrygroup',\n",
    "       'industry', 'securityname', 'maturitydate', 'underlyingname',\n",
    "       'regionname', 'issuercountryofrisk']\n",
    "    \n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(securities_cols)\n",
    "    \n",
    "    added = 0\n",
    "    for i in security_universe.index:\n",
    "        row = []\n",
    "        for col in securities_cols: \n",
    "            row.append(security_universe[col][i])\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa5bfa4",
   "metadata": {},
   "source": [
    "## 2. Generate a Position Snapshot\n",
    "Now we need a dataset that simulates the holdings of the firm at any given point in time. This data will identify each trader's  holdings by security ID, with a `quantity` (# of units of the security) associated with each holding.\n",
    "### Disclaimer\n",
    "This is a purely random set of hypothetical positions and has no relationship to MLP's actual positions at present or at any point in the past."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c8375a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 200   80 -170  -90  120]\n"
     ]
    }
   ],
   "source": [
    "def generate_random_position_quantities(n_samples, mean=0, std_dev=100):\n",
    "    \"\"\"\n",
    "    Generates a random set of quantities to use for the positions, using a Gaussian approach but set to output\n",
    "    fairly round numbers.\n",
    "    \"\"\"\n",
    "    # Generate extra samples to account for the ones we'll remove\n",
    "    samples = np.random.normal(mean, std_dev / 10, size=int(n_samples*1.4))\n",
    "    \n",
    "    # Round to nearest whole number of tens\n",
    "    samples = np.round(samples).astype(int) * 10\n",
    "    \n",
    "    # Remove zeros, a zero position is not an active position and should be ignored\n",
    "    samples = samples[samples != 0]\n",
    "    \n",
    "    # Trim the array to the desired size\n",
    "    samples = samples[:n_samples]\n",
    "    \n",
    "    return samples\n",
    "\n",
    "quantities = generate_random_position_quantities(n_samples=n_positions)\n",
    "print(quantities[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0c283e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_samples_bucketed(n_samples, distinct_strings, parent):\n",
    "    \"\"\"\n",
    "    Generates the desired number of samples from a provided list of distinct strings, such that the frequencies of the \n",
    "    samples are Gaussian and not uniform, AND such that each occurrence of a given string in the output array occurs in\n",
    "    a position containing the same value in the input \"parent\" array.\n",
    "\n",
    "    Args:\n",
    "        n_samples (int): The number of samples to generate.\n",
    "        distinct_strings (list): The list of distinct strings to sample from.\n",
    "        parent (list): The list of parent values. Each unique value in this list corresponds to a distinct subset of \n",
    "                       distinct_strings.\n",
    "\n",
    "    Returns:\n",
    "        list: The generated samples.\n",
    "    \"\"\"\n",
    "    # Create a probability distribution that approximates a Gaussian distribution\n",
    "    n_distinct = len(distinct_strings)\n",
    "    mean = n_distinct / 2\n",
    "    std_dev = n_distinct / 4  # Arbitrary choice, you can adjust this\n",
    "    x = np.linspace(0, n_distinct - 1, n_distinct)\n",
    "    weights = np.exp(-((x - mean) ** 2) / (2 * std_dev ** 2))\n",
    "    weights /= np.sum(weights)  # Normalize the weights so they sum up to 1\n",
    "\n",
    "    # Create a mapping from each unique parent value to a distinct subset of distinct_strings\n",
    "    unique_parents = np.unique(parent)\n",
    "    n_unique = len(unique_parents)\n",
    "    subset_size = n_distinct // n_unique\n",
    "    subsets = {p: distinct_strings[i*subset_size:(i+1)*subset_size] for i, p in enumerate(unique_parents)}\n",
    "    subset_weights = {p: weights[i*subset_size:(i+1)*subset_size] for i, p in enumerate(unique_parents)}\n",
    "    for p in unique_parents:\n",
    "        subset_weights[p] /= subset_weights[p].sum()  # Normalize the weights for each subset\n",
    "\n",
    "    # Generate the samples\n",
    "    samples = [np.random.choice(subsets[parent[i]], p=subset_weights[parent[i]]) for i in range(n_samples)]\n",
    "\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "605d4ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done generating desks\n",
      "Done generating pods\n",
      "Done generating traders\n",
      "Done generating micros\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>securityid</th>\n",
       "      <th>trader</th>\n",
       "      <th>microstrategy</th>\n",
       "      <th>pod</th>\n",
       "      <th>desk</th>\n",
       "      <th>supervisor</th>\n",
       "      <th>quantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>YE8AV40Z</td>\n",
       "      <td>1XS3KOD8</td>\n",
       "      <td>PZSIKZM2</td>\n",
       "      <td>XA1V5EH9</td>\n",
       "      <td>5R6QR2L9</td>\n",
       "      <td>Commod</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>89HNLZDP</td>\n",
       "      <td>J3C2A6II</td>\n",
       "      <td>SCOS81Y2</td>\n",
       "      <td>D3SFZXBG</td>\n",
       "      <td>I22Q0W84</td>\n",
       "      <td>Commod</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PHJY55AG</td>\n",
       "      <td>HB6RIBED</td>\n",
       "      <td>QIEAKT7U</td>\n",
       "      <td>BPSKBLAX</td>\n",
       "      <td>Q2TZVQJK</td>\n",
       "      <td>Fixed Income</td>\n",
       "      <td>-170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5W4LJGN4</td>\n",
       "      <td>L19RYQ3A</td>\n",
       "      <td>FWW4RDDH</td>\n",
       "      <td>XCFX9L3D</td>\n",
       "      <td>9LZBU75X</td>\n",
       "      <td>Quant Arb</td>\n",
       "      <td>-90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RPRP5ZXO</td>\n",
       "      <td>F8L7ZCMM</td>\n",
       "      <td>2FRVB1RJ</td>\n",
       "      <td>Z7EWQ5DK</td>\n",
       "      <td>JFQRCCHV</td>\n",
       "      <td>Other</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  securityid    trader microstrategy       pod      desk    supervisor  \\\n",
       "0   YE8AV40Z  1XS3KOD8      PZSIKZM2  XA1V5EH9  5R6QR2L9        Commod   \n",
       "1   89HNLZDP  J3C2A6II      SCOS81Y2  D3SFZXBG  I22Q0W84        Commod   \n",
       "2   PHJY55AG  HB6RIBED      QIEAKT7U  BPSKBLAX  Q2TZVQJK  Fixed Income   \n",
       "3   5W4LJGN4  L19RYQ3A      FWW4RDDH  XCFX9L3D  9LZBU75X     Quant Arb   \n",
       "4   RPRP5ZXO  F8L7ZCMM      2FRVB1RJ  Z7EWQ5DK  JFQRCCHV         Other   \n",
       "\n",
       "   quantity  \n",
       "0       200  \n",
       "1        80  \n",
       "2      -170  \n",
       "3       -90  \n",
       "4       120  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supervisors = generate_samples(n_positions, [\"Fundamental EQ\", \"Fixed Income\", \"Quant Arb\", \"Commod\", \"Other\"])\n",
    "\n",
    "desks = generate_samples_bucketed(n_positions, generate_random_strings(n_desks, 8), parent=supervisors)\n",
    "print(\"Done generating desks\")\n",
    "\n",
    "pods = generate_samples_bucketed(n_positions, generate_random_strings(n_pods, 8), parent=desks)\n",
    "print(\"Done generating pods\")\n",
    "\n",
    "traders = generate_samples_bucketed(n_positions, generate_random_strings(n_traders, 8), parent=pods)\n",
    "print(\"Done generating traders\")\n",
    "\n",
    "microstrategies = generate_samples_bucketed(n_positions, generate_random_strings(n_micros, 8), parent=traders)\n",
    "print(\"Done generating micros\")\n",
    "\n",
    "positions = pd.DataFrame({\n",
    "    \"securityid\": generate_samples(n_positions, security_id_space),\n",
    "    \"trader\": traders,\n",
    "    \"microstrategy\": microstrategies,\n",
    "    \"pod\": pods,\n",
    "    \"desk\": desks,\n",
    "    \"supervisor\": supervisors,\n",
    "    \"quantity\": quantities\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "feeb7e61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['securityid', 'trader', 'microstrategy', 'pod', 'desk', 'supervisor',\n",
       "       'quantity'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "positions.head()\n",
    "positions.shape # 2,000,000 x 7 \n",
    "positions.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cda0ddc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pod\n",
      "791JLCAB    28058\n",
      "1RGMSJGH    26904\n",
      "D0H4U6N5    26239\n",
      "Name: count, dtype: int64\n",
      "pod\n",
      "EOC1R967    9044\n",
      "I0WY3H37    8892\n",
      "9W16Q6G1    8854\n",
      "Name: count, dtype: int64\n",
      "pod\n",
      "LSBGJQGO    2031\n",
      "JA3RTK5G    2024\n",
      "68E1V89Y    2010\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check the distribution shape\n",
    "print(positions['pod'].value_counts()[:3])\n",
    "print(positions['pod'].value_counts()[99:102])\n",
    "print(positions['pod'].value_counts()[-3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2fbf76aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>securityid</th>\n",
       "      <th>trader</th>\n",
       "      <th>microstrategy</th>\n",
       "      <th>pod</th>\n",
       "      <th>desk</th>\n",
       "      <th>supervisor</th>\n",
       "      <th>quantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>250055</th>\n",
       "      <td>5KZAHWDR</td>\n",
       "      <td>V35P78QE</td>\n",
       "      <td>XU9L4UF4</td>\n",
       "      <td>LSBGJQGO</td>\n",
       "      <td>KNTAIU34</td>\n",
       "      <td>Fundamental EQ</td>\n",
       "      <td>-60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262282</th>\n",
       "      <td>Z56Z3HZP</td>\n",
       "      <td>V35P78QE</td>\n",
       "      <td>XU9L4UF4</td>\n",
       "      <td>LSBGJQGO</td>\n",
       "      <td>KNTAIU34</td>\n",
       "      <td>Fundamental EQ</td>\n",
       "      <td>-50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548251</th>\n",
       "      <td>Y4UGZEIL</td>\n",
       "      <td>V35P78QE</td>\n",
       "      <td>XU9L4UF4</td>\n",
       "      <td>LSBGJQGO</td>\n",
       "      <td>KNTAIU34</td>\n",
       "      <td>Fundamental EQ</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592355</th>\n",
       "      <td>0KOFAEP8</td>\n",
       "      <td>V35P78QE</td>\n",
       "      <td>XU9L4UF4</td>\n",
       "      <td>LSBGJQGO</td>\n",
       "      <td>KNTAIU34</td>\n",
       "      <td>Fundamental EQ</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>821427</th>\n",
       "      <td>AATRDG7Q</td>\n",
       "      <td>V35P78QE</td>\n",
       "      <td>XU9L4UF4</td>\n",
       "      <td>LSBGJQGO</td>\n",
       "      <td>KNTAIU34</td>\n",
       "      <td>Fundamental EQ</td>\n",
       "      <td>-80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>838907</th>\n",
       "      <td>TBFO7K14</td>\n",
       "      <td>V35P78QE</td>\n",
       "      <td>XU9L4UF4</td>\n",
       "      <td>LSBGJQGO</td>\n",
       "      <td>KNTAIU34</td>\n",
       "      <td>Fundamental EQ</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1061317</th>\n",
       "      <td>0HSM0M76</td>\n",
       "      <td>V35P78QE</td>\n",
       "      <td>XU9L4UF4</td>\n",
       "      <td>LSBGJQGO</td>\n",
       "      <td>KNTAIU34</td>\n",
       "      <td>Fundamental EQ</td>\n",
       "      <td>-50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1345565</th>\n",
       "      <td>PR0ANKG0</td>\n",
       "      <td>V35P78QE</td>\n",
       "      <td>XU9L4UF4</td>\n",
       "      <td>LSBGJQGO</td>\n",
       "      <td>KNTAIU34</td>\n",
       "      <td>Fundamental EQ</td>\n",
       "      <td>-70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1461110</th>\n",
       "      <td>7P2LXLAA</td>\n",
       "      <td>V35P78QE</td>\n",
       "      <td>XU9L4UF4</td>\n",
       "      <td>LSBGJQGO</td>\n",
       "      <td>KNTAIU34</td>\n",
       "      <td>Fundamental EQ</td>\n",
       "      <td>-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        securityid    trader microstrategy       pod      desk  \\\n",
       "250055    5KZAHWDR  V35P78QE      XU9L4UF4  LSBGJQGO  KNTAIU34   \n",
       "262282    Z56Z3HZP  V35P78QE      XU9L4UF4  LSBGJQGO  KNTAIU34   \n",
       "548251    Y4UGZEIL  V35P78QE      XU9L4UF4  LSBGJQGO  KNTAIU34   \n",
       "592355    0KOFAEP8  V35P78QE      XU9L4UF4  LSBGJQGO  KNTAIU34   \n",
       "821427    AATRDG7Q  V35P78QE      XU9L4UF4  LSBGJQGO  KNTAIU34   \n",
       "838907    TBFO7K14  V35P78QE      XU9L4UF4  LSBGJQGO  KNTAIU34   \n",
       "1061317   0HSM0M76  V35P78QE      XU9L4UF4  LSBGJQGO  KNTAIU34   \n",
       "1345565   PR0ANKG0  V35P78QE      XU9L4UF4  LSBGJQGO  KNTAIU34   \n",
       "1461110   7P2LXLAA  V35P78QE      XU9L4UF4  LSBGJQGO  KNTAIU34   \n",
       "\n",
       "             supervisor  quantity  \n",
       "250055   Fundamental EQ       -60  \n",
       "262282   Fundamental EQ       -50  \n",
       "548251   Fundamental EQ        10  \n",
       "592355   Fundamental EQ       100  \n",
       "821427   Fundamental EQ       -80  \n",
       "838907   Fundamental EQ        40  \n",
       "1061317  Fundamental EQ       -50  \n",
       "1345565  Fundamental EQ       -70  \n",
       "1461110  Fundamental EQ       -10  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check fidelity of hierarchy assignments\n",
    "# All occurrences of a given microstrategy should fall under the same trader, pod, desk and supervisor\n",
    "\n",
    "smallest_microstrategy = positions['microstrategy'].value_counts()[-1:].index[-1]\n",
    "positions[positions['microstrategy'] == smallest_microstrategy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "795665d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a csv for positions \n",
    "with open('./data/positions.csv', 'w', newline='') as csvfile:\n",
    "    # columns for the securities dataframe (security_universe.columns)\n",
    "    position_cols = ['securityid', 'trader', 'microstrategy', 'pod', 'desk', 'supervisor', 'quantity']\n",
    "    \n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(position_cols)\n",
    "    \n",
    "    added = 0\n",
    "    for i in positions.index:\n",
    "        row = []\n",
    "        for col in position_cols: \n",
    "            row.append(positions[col][i])\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b97e16",
   "metadata": {},
   "source": [
    "## 3. Generate the historical simulated PnL for each security \n",
    "The backbone of our VaR calculations is a dataset consisting of a set of simulated per-unit price changes (P&L) in response to all daily market moves observed during the last ~15 years, for each of the 200K securities in our tradable universe. \n",
    "\n",
    "A single row in this dataset may be interpreted as follows:\n",
    "```\n",
    "securityid   date        pnl\n",
    "WDANCZU5     2024-01-03  -381.4\n",
    "```\n",
    "--> \"If the same relative market movements that happened between close of business 2024-01-02 and close of business 2024-01-03 were to happen between yesterday's market close and today's market close, the market price of a single unit of security WDANCZU5 will decrease by $381.40.\"\n",
    "\n",
    "Here, the data volume gets too large to keep in dataframes (5,000 dates * 200,000 securities = 1,000,000,000 total rows), so we'll write out to the disk. Make sure you have plenty of hard drive space before running this step.\n",
    "\n",
    "### Disclaimer\n",
    "\n",
    "Although we will use the term \"PnL\" to describe this dataset, it is purely random and hypothetical, and has no relationship to the PnL ever experienced by any security or position held by MLP or otherwise, now or at any time in the past."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ccae4571",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2008-01-01', '2008-01-02', '2008-01-03', '2008-01-04', '2008-01-07', '2008-01-08', '2008-01-09', '2008-01-10']\n"
     ]
    }
   ],
   "source": [
    "# Generate the historical simulation dates: all weekdays since 2008\n",
    "\n",
    "start_date = datetime(2008, 1, 1)\n",
    "end_date = datetime.now()\n",
    "weekdays = []\n",
    "\n",
    "for n in range(int ((end_date - start_date).days)):\n",
    "    current_date = start_date + timedelta(n)\n",
    "    # Check if current day is a weekday (0: Monday, 1: Tuesday, ..., 4: Friday)\n",
    "    if current_date.weekday() < 5:\n",
    "        # Append the date in \"YYYY-MM-DD\" format\n",
    "        weekdays.append(current_date.strftime('%Y-%m-%d'))\n",
    "\n",
    "print(weekdays[:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b068140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We're going to use a Student's T with degrees of freedom = 3 to generate the simulated PnL. We don't want to use\n",
    "# a Gaussian for this as real life PnL is not Gaussian (if it were, risk management for hedge funds would be much simpler).\n",
    "\n",
    "degrees_of_freedom = 3  # fat tail\n",
    "t_distribution = t(3)\n",
    "standard_deviation = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e5c73ea0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'weekdays' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m debug_lines \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m security_id \u001b[38;5;129;01min\u001b[39;00m security_id_space:\n\u001b[0;32m----> 7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m weekday \u001b[38;5;129;01min\u001b[39;00m \u001b[43mweekdays\u001b[49m:\n\u001b[1;32m      8\u001b[0m         row \u001b[38;5;241m=\u001b[39m [security_id, weekday, \u001b[38;5;28mround\u001b[39m(t_distribution\u001b[38;5;241m.\u001b[39mrvs() \u001b[38;5;241m*\u001b[39m standard_deviation, \u001b[38;5;241m2\u001b[39m)]\n\u001b[1;32m      9\u001b[0m         writer\u001b[38;5;241m.\u001b[39mwriterow(row)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'weekdays' is not defined"
     ]
    }
   ],
   "source": [
    "with open('simulated_pnl.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['securityid', 'date', 'pnl'])\n",
    "    \n",
    "    debug_lines = 0\n",
    "    for security_id in security_id_space:\n",
    "        for weekday in weekdays:\n",
    "            row = [security_id, weekday, round(t_distribution.rvs() * standard_deviation, 2)]\n",
    "            writer.writerow(row)\n",
    "            \n",
    "            if debug_lines < 10:\n",
    "                print(row)\n",
    "            \n",
    "            debug_lines += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befd2226",
   "metadata": {},
   "source": [
    "## 4. Spec out the queries that the system will need to support\n",
    "We want to build a system that can serve up percentiles of the above data, applying filters to one or more of the position or security columns to select a sub-population, aggregating to one or more of the columns, and then computing a percentile at each level of the aggregation. For example:\n",
    "```\n",
    "select\n",
    "    p.desk, p.pod, s.assetclass, percentile(0.05, x.pnl)\n",
    "from\n",
    "    position p, security s, simulated_pnl x\n",
    "where\n",
    "    p.securityid = s.securityid and x.securityid = s.securityid\n",
    "    and p.supervisor = 'Fundamental EQ'\n",
    "    and s.tradingcountry = 'US'\n",
    "group by\n",
    "    p.desk, p.pod, p.assetclass\n",
    "```\n",
    "Note that your implementation **does not** need to actually take SQL as input! You are free to define the API as you choose, it could be JSON, GraphQL, etc.\n",
    "\n",
    "### Functional and Performance Requirements\n",
    "\n",
    "1. Given a multi-threaded workload consisting of heterogeneous queries like the above, the system should be able to maintain a **1 qps (query per second) throughput under load**. You will need to build a test harness to generate heterogeneous queries with different filters and aggregation dimensions in your chosen API input format.\n",
    "1. The system is allowed to impose a hard limit of 100K output rows per query. Very large aggregations (e.g. those resulting from a \"group by\" on multiple high-cardinality dimensions) are not a typical use case and the response payload may be too large for the client to handle anyway. The system may return a 400 Bad Request error if it detects that the output will be >100K rows.\n",
    "1. The typical percentiles users will need are 0.01, 0.05, 0.95, 0.99, min and max. If your API design and architecture support free-form percentiles, then fine, but if not, you are free to support only these values as a fixed enum.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0872e463",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
